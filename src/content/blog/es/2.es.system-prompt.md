---
title: "System prompt, configura tu asistente"
subtitle: "Preséntate, aporta contexto y declara expectativas."
description: "Aprende a configurar tu asistente virtual con tecnicas de 'prompt engineering' para personalizar su comportamiento y mejorar la interacción"
slug: "system-prompt-configura-tu-asistente"
category: "procedimientos"
date: "2024-10-14"
---

## Preséntate, aporta contexto y declara expectativas.

Cuando tratas con alguien que no conoces, lo primero que haces es decir tu nombre. Tu apariencia y lenguaje corporal también dicen mucho de ti. Inmediatamente pides, preguntas o informas sobre algo. Es un **proceso en tres pasos automático** entre personas. Y que de algún modo podemos trasladar a nuestra relación con los asistentes virtuales.

> Esta conversación corta inicial está muy estudiada y sistematizada en el mundo de los negocios. Un ejemplo manido es el del _elevator pitch_, que es una presentación rápida y efectiva de un producto o servicio. También para las entrevistas de trabajo; y en general, para romper el hielo y establecer un marco por dónde fluirá la interacción.

Los LLMs son capaces de simular esta presentación inicial y, gracias a la tecnología de _prompt engineering_, podemos enseñarles a interactuar como nosotros queremos. Algunos como [ChatGPT](https://chatgpt.com) o [Perplexity](https://www.perplexity.ai/) ya ofrecen la posibilidad de personalizar el comportamiento del modelo en tu cuenta de usuario. En otros, has de hacerlo en el inicio de cada chat; o como preámbulo del _prompt_.

Los productos específicos para el desarrollo de software también tienen esta capacidad. Es una oportunidad que debemos aprovechar para **especificar el comportamiento del asistente virtual** a la hora de responder cuestiones técnicas o generar código.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1731404322749/4eb96335-8b50-4d00-b253-5c16b99c323a.png)

## El ejemplo de Íñigo Montoya

Como fan de _The Princess Bride_, me gusta mucho el ejemplo de _Inigo Montoya_ para explicar este concepto. Este sistema ha sido incluso objeto de estudio en universidades. Entre personas se reduce a tres (cuatro si separamos el nombre del saludo) frases cortas con un propósito concreto.

1. **Presentación**: _Hola, me llamo Íñigo Montoya._
2. **Contexto**: _Tú mataste a mi padre._
3. **Propósito**: _Prepárate a morir._

Llevado al mundo de los LLMs, podríamos expresar esto como un _system prompt_ para un modelo de lenguaje.

```typescript
# Presentación
Hola, me llamo Íñigo Montoya.

# Contexto
Tú mataste a mi padre.

# Propósito
Prepárate a morir.
```

Ya, ya paro, es que no puedo evitarlo. Ahora va aplicado a la IA para desarrolladores.

## La configuración del sistema

Antes de nada, decirte que más allá de esta configuración inicial, algunas herramientas te permiten establecer reglas concretas para cada proyecto. Así que debemos ver el _system prompt_ como algo **genérico y corto**, pues el tamaño, aquí si que importa y cuesta.

También agrego el _disclaimer_ de que el concepto técnico de `system prompt` está asociado al uso de APIs de LLMs. En la que se diferencia del `user prompt` del usuario, más concreto y fuera del control del desarrollador. Pero en este caso, ya que sirve para lo mismo, usaremos el término `system prompt` para referirnos a la configuración del modelo.

Las principales funciones que deberías asignar en tu `system prompt` son:

- Establecer el rol del asistente (ayudante, mentor, experto, etc.)
- Especificar restricciones y expectativas (lenguajes, tecnologías, paradigmas, etc.)
- Promover la consistencia en las respuestas (idiomas, formatos, tono etc.)

Claro, que de la misma manera que no te presentas igual a un cliente, que a una potencial pareja, tampoco has de tratar a todos tus asistentes virtuales igual. Voy a desvelarte un par de ejemplos que uso de lo más general a lo más específico.

### Generalista para ChatGPT o Perplexity

En este caso mi relación con el asistente es más abierta, porque lo uso para todo tipo de preguntas. Así que hablo más de mi que de él.

```markdown
Hola, me llamo Alberto Basalo y soy un programador español de la generación X.

Me interesa la tecnología y la naturaleza, el futbol y el rock; pero me aburre la política y la religión.

Ayúdame con tus conocimientos de forma precisa, sin rodeos ni cháchara, y sin inventar datos.
```

### Específico para desarrollo

Cuando uso el asistentes de desarrollo (como [Cursor](https://cursor.com) o [Copilot](https://copilot.github.com)), mi relación con él es más cerrada.

```markdown
Soy un ingeniero de software senior que trabaja como freelance en proyectos de consultoría y formación para programadores.

Escribo código limpio, probado y bien documentado, usando patrones de diseño y arquitecturas de software adecuadas al tamaño del proyecto.

Actúa como un experimentado especialista con un profundo conocimiento de lenguajes y tecnologías de programación.

Ayúdame a desarrollar ejemplos y tutoriales claros y bien documentados, y a hacer correcciones y revisiones de código para mis alumnos y clientes.
```

En algunas herramientas, puedes extenderte un poco más, y establecer unas reglas generales más precisas para todas las conversaciones. Por ejemplo:

```markdown
- Contéstame en inglés, aunque te pregunte en español.
- Se escueto y directo, sin preámbulos ni despedidas educadas.
- No me expliques fundamentos ni conceptos básicos.
- Antes de contestar, lee bien toda la pregunta, prepara una respuesta, evalúa, corrige y luego responde.
- Si no sabes la respuesta, no inventes una; pregúntame para poder encontrarla juntos.
- Completa todas las tareas que se te encarguen, sin dejar nada sin hacer.
- Ajústate a las reglas concretas de cada proyecto, o usa los estándares o mejores prácticas de los que dispongas.
```

### Aún más específico y detallado para cada proyecto

Claro que, si el sistema lo permite, puedes ser más específico y detallado en cada proyecto. Dedicaré una entrada específica para ello. [Suscríbete a mi newsletter](https://es.aiddbot.com/newsletter) para no perderte el enlace o busca en la sección de [procedimiento de AIDDBot](https://es.aiddbot.com/series/procedimientos) por si ya lo he publicado.

## Conclusión

Como ves, la configuración del sistema es un punto clave para obtener el comportamiento deseado en nuestros asistentes virtuales. Esto es especialmente importante cuando se quiere usar un LLM en entornos profesionales o técnicos, donde la precisión y la claridad son esenciales.Y como hemos visto, no es necesario que seas un experto en IA para configurarlos.

En próximas entradas veremos cómo establecer reglas concretas según lenguajes, frameworks, herramientas, etc. Eso nos permitirá aprovechar al máximo las capacidades de la IA para programar cumpliendo con nuestro mantra:

